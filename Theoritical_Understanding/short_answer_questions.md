# Q1: Explain the primary differences between TensorFlow and PyTorch. When would you choose one over the other?
TensorFlow and PyTorch are both leading deep learning frameworks, yet they differ fundamentally in their approach. While TensorFlow traditionally employs a static computational graph where the entire network must be defined and compiled before execution, PyTorch utilizes a dynamic graph that is built on-the-fly during runtime, making it more intuitive for debugging and prototyping. Consequently, TensorFlow often excels in production environments due to its robust deployment tools and optimization for scalable systems. In contrast, PyTorch is frequently preferred in research and academic settings for its Pythonic syntax and flexibility. Therefore, you would choose TensorFlow for deploying models to mobile devices or servers where stability is key, whereas you would select PyTorch for rapid experimentation and development where ease of use is a priority.

# Q2: Describe two use cases for Jupyter Notebooks in AI development.
Jupyter Notebooks serve as an essential tool in AI development, particularly for iterative and exploratory tasks. One primary use case is exploratory data analysis, where a data scientist can interactively visualize datasets, compute statistics, and clean data within a single environment, thereby gaining immediate insights and guiding subsequent steps. Another critical use case is model prototyping and training; since notebooks allow for the execution of code in discrete cells, developers can quickly build a model, evaluate its performance, and then refine its architecture or hyperparameters in subsequent cells without rerunning the entire script. As a result, this facilitates a seamless workflow from experimentation to documentation, making the development process both efficient and reproducible.

# Q3: How does spaCy enhance NLP tasks compared to basic Python string operations?
spaCy significantly enhances natural language processing tasks by moving beyond simple pattern matching to providing deep linguistic understanding. While basic string operations in Python are limited to identifying explicit character sequences, spaCy uses statistical models to interpret context, enabling it to distinguish between different meanings of the same word based on surrounding text. Furthermore, whereas string methods lack grammatical awareness, spaCy automatically annotates text with part-of-speech tags, dependency trees, and lemmas, thereby revealing the syntactic structure and relationships within sentences. Consequently, for complex tasks such as named entity recognition or sentiment analysis, spaCy offers a level of accuracy and efficiency that manual string manipulation cannot realistically achieve.

